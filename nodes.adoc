= Nodes

toc::[]


## Configuring your cluster to place pods on overcommitted nodes

[source,terminal]
----
$ oc create -f <file-name>.yaml
----


[source,terminal]
----
$ oc create -f cro-namespace.yaml
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----


[source,terminal]
----
$ oc create -f cro-og.yaml
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----


[source,terminal]
----
$ oc create -f cro-sub.yaml
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----


[source,terminal]
----
$ oc create -f cro-cr.yaml
----


[source,terminal]
----
$ oc label machineconfigpool worker custom-kubelet=small-pods
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----

## Configuring an {product-title} cluster for pods

[source,terminal]
----
$ oc create -f <file_or_dir_path>
----


[source,terminal]
----
$ oc create -f </path/to/file> -n <project_name>
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----

## Configuring cluster memory to meet container memory and risk requirements

[source,terminal]
----
$ oc create -f <file-name>.yaml
----

## Estimating the number of pods your {product-title} nodes can hold

[source,terminal]
----
$ oc create sa cluster-capacity-sa
----


[source,terminal]
----
$ oc adm policy add-cluster-role-to-user cluster-capacity-role \
    system:serviceaccount:default:cluster-capacity-sa
----


[source,terminal]
----
$ oc create -f cluster-capacity-job.yaml
----

## Allowing containers to consume API objects

[source,terminal]
----
$ oc create -f pod.yaml
----


[source,terminal]
----
$ oc create -f volume-pod.yaml
----


[source,terminal]
----
$ oc create -f pod.yaml
----


[source,terminal]
----
$ oc create -f volume-pod.yaml
----


[source,terminal]
----
$ oc create -f secret.yaml
----


[source,terminal]
----
$ oc create -f pod.yaml
----


[source,terminal]
----
$ oc create -f configmap.yaml
----


[source,terminal]
----
$ oc create -f pod.yaml
----


[source,terminal]
----
$ oc create -f pod.yaml
----


[source,terminal]
----
$ oc create -f pod.yaml
----

## Using Init Containers to perform tasks before a pod is deployed

[source,terminal]
----
$ oc create -f myapp.yaml
----


[source,terminal]
----
$ oc create -f mydb.yaml
----


[source,terminal]
----
$ oc create -f myservice.yaml
----

## Using port forwarding to access applications in a container

[source,terminal]
----
$ oc port-forward <pod> [<local_port>:]<remote_port> [...[<local_port_n>:]<remote_port_n>]
----


[source,terminal]
----
$ oc port-forward <pod> [<local_port>:]<remote_port> [...[<local_port_n>:]<remote_port_n>]
----


[source,terminal]
----
$ oc port-forward <pod> 5000 6000
----


[source,terminal]
----
$ oc port-forward <pod> 8888:5000
----


[source,terminal]
----
$ oc port-forward <pod> :5000
----


[source,terminal]
----
$ oc port-forward <pod> 0:5000
----

## Mapping volumes using projected volumes

[source,terminal]
----
$ oc create -f <secrets-filename>
----


[source,terminal]
----
$ oc create -f secret.yaml
----


[source,terminal]
----
$ oc create -f <your_yaml_file>.yaml
----


[source,terminal]
----
$ oc create -f secret-pod.yaml
----

## Using sysctls in containers

[source,terminal]
----
$ oc apply -f <file-name>.yaml
----


[source,terminal]
----
$ oc edit machineconfigpool worker
----


[source,terminal]
----
$ oc apply -f set-sysctl-worker.yaml
----

## Using volumes to persist container data

[source,terminal]
----
$ oc set volume <object_selection> <operation> <mandatory_parameters> <options>
----


[source,terminal]
----
$ oc set volume <object_type>/<name> [options]
----


[source,terminal]
----
$ oc set volume pod/p1
----


[source,terminal]
----
$ oc set volume dc --all --name=v1
----


[source,terminal]
----
$ oc set volume <object_type>/<name> --add [options]
----


[source,terminal]
----
$ oc set volume dc/registry --add
----


[source,terminal]
----
$ oc set volume rc/r1 --add --name=v1 --type=secret --secret-name='secret1' --mount-path=/data
----


[source,terminal]
----
$ oc set volume -f dc.json --add --name=v1 --type=persistentVolumeClaim \
  --claim-name=pvc1 --mount-path=/data --containers=c1
----


[source,terminal]
----
$ oc set volume rc --all --add --name=v1 \
  --source='{"gitRepo": {
                "repository": "https://github.com/namespace1/project1",
                "revision": "5125c45f9f563"
            }}'
----


[source,terminal]
----
$ oc set volume <object_type>/<name> --add --overwrite [options]
----


[source,terminal]
----
$ oc set volume rc/r1 --add --overwrite --name=v1 --type=persistentVolumeClaim --claim-name=pvc1
----


[source,terminal]
----
$ oc set volume dc/d1 --add --overwrite --name=v1 --mount-path=/opt
----


[source,terminal]
----
$ oc set volume <object_type>/<name> --remove [options]
----


[source,terminal]
----
$ oc set volume dc/d1 --remove --name=v1
----


[source,terminal]
----
$ oc set volume dc/d1 --remove --name=v1 --containers=c1
----


[source,terminal]
----
$ oc set volume rc/r1 --remove --confirm
----

## Running tasks in pods using jobs

[source,terminal]
----
$ oc delete cronjob/<cron_job_name>
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----


[source,terminal]
----
$ oc create job pi --image=perl -- perl -Mbignum=bpi -wle 'print bpi(2000)'
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----


[source,terminal]
----
$ oc create cronjob pi --image=perl --schedule='*/1 * * * *' -- perl -Mbignum=bpi -wle 'print bpi(2000)'
----

## Running background tasks on nodes automatically with daemon sets

[source,terminal]
----
$ oc patch namespace myproject -p \
    '{"metadata": {"annotations": {"openshift.io/node-selector": ""}}}'
----


[source,terminal]
----
$ oc create -f daemonset.yaml
----

## Freeing node resources using garbage collection

[source,terminal]
----
$ oc label machineconfigpool worker custom-kubelet=small-pods
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----


[source,terminal]
----
$ oc create -f gc-container.yaml
----

## Managing the maximum number of pods per node

[source,terminal]
----
$ oc label machineconfigpool worker custom-kubelet=small-pods
----

## Managing nodes

[source,terminal]
----
$ oc label machineconfigpool worker custom-kubelet=enabled
----


[source,terminal]
----
$ oc create -f <file-name>
----


[source,terminal]
----
$ oc create -f master-kube-config.yaml
----

## Modifying existing nodes in your {product-title} cluster

[source,terminal]
----
$ oc adm cordon <node>
----


[source,terminal]
----
$ oc adm cordon node1.example.com
----


[source,terminal]
----
$ oc adm uncordon <node1>
----

## Allocating resources for nodes in an {product-title} cluster

[source,terminal]
----
$ oc label machineconfigpool worker custom-kubelet=small-pods
----


[source,terminal]
----
$ oc label machineconfigpool worker custom-kubelet=small-pods
----

## Allocating specific CPUs for nodes in a cluster

[source,terminal]
----
$ oc create -f <file_name>.yaml
----

## Viewing and listing the nodes in your {product-title} cluster

[source,terminal]
----
$ oc adm top nodes
----


[source,terminal]
----
$ oc adm top node --selector=''
----

## Working with nodes

[source,terminal]
----
$ oc adm cordon <node1>
----


[source,terminal]
----
$ oc adm drain <node1> <node2> [--pod-selector=<pod_selector>]
----


[source,terminal]
----
$ oc adm drain <node1> <node2> --force=true
----


[source,terminal]
----
$ oc adm drain <node1> <node2> --grace-period=-1
----


[source,terminal]
----
$ oc adm drain <node1> <node2> --ignore-daemonsets=true
----


[source,terminal]
----
$ oc adm drain <node1> <node2> --timeout=5s
----


[source,terminal]
----
$ oc adm drain <node1> <node2> --delete-local-data=true
----


[source,terminal]
----
$ oc adm drain <node1> <node2>  --dry-run=true
----


[source,terminal]
----
$ oc adm uncordon <node1>
----


[source,terminal]
----
$ oc label node <node> <key_1>=<value_1> ... <key_n>=<value_n>
----


[source,terminal]
----
$ oc label nodes webconsole-7f7f6 unhealthy=true
----


[source,terminal]
----
$ oc label pods --all <key_1>=<value_1>
----


[source,terminal]
----
$ oc adm cordon <node>
----


[source,terminal]
----
$ oc adm cordon node1.example.com
----


[source,terminal]
----
$ oc adm uncordon <node1>
----


[source,terminal]
----
$ oc edit schedulers.config.openshift.io cluster
----


[source,terminal]
----
$ oc scale --replicas=2 machineset <machineset> -n openshift-machine-api
----


[source,terminal]
----
$ oc adm cordon <node_name>
----


[source,terminal]
----
$ oc adm drain <node_name> --force=true
----


[source,terminal]
----
$ oc delete node <node_name>
----


[source,terminal]
----
$ oc create -f 05-worker-kernelarg-selinuxoff.yaml
----

## Automatically scaling pods with the horizontal pod autoscaler

[source,terminal]
----
$ oc edit hpa hpa-resource-metrics-memory
----


[source,terminal]
----
$ oc autoscale dc/<dc-name> \
  --min <number> \
  --max <number> \
  --cpu-percent=<percent> 
----


[source,terminal]
----
$ oc autoscale rc/<rc-name> 
  --min <number> \
  --max <number> \
  --cpu-percent=<percent> 
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----


[source,terminal]
----
$ oc autoscale dc/image-registry --min 3 --max 7 --cpu-percent=75
----


[source,terminal]
----
$ oc edit hpa frontend -n openshift-image-registry
----


[source,terminal]
----
$ oc autoscale dc/image-registry --min=5 --max=7 --cpu-percent=75
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----


[source,terminal]
----
$ oc create -f hpa.yaml
----

## Configuring an {product-title} cluster for pods

[source,terminal]
----
$ oc create -f <file_or_dir_path>
----


[source,terminal]
----
$ oc create -f </path/to/file> -n <project_name>
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----

## Placing pods on specific nodes using node selectors

[source,terminal]
----
$ oc patch MachineSet <name> --type='json' -p='[{"op":"add","path":"/spec/template/spec/metadata/labels", "value":{"<key>"="<value>","<key>"="<value>"}}]'  -n openshift-machine-api
----


[source,terminal]
----
$ oc patch MachineSet abc612-msrtw-worker-us-east-1c  --type='json' -p='[{"op":"add","path":"/spec/template/spec/metadata/labels", "value":{"type":"user-node","region":"east"}}]'  -n openshift-machine-api
----


[source,terminal]
----
$ oc edit MachineSet abc612-msrtw-worker-us-east-1c -n openshift-machine-api
----


[source,terminal]
----
$ oc label nodes <name> <key>=<value>
----


[source,terminal]
----
$ oc label nodes ip-10-0-142-25.ec2.internal type=user-node region=east
----

## Using device plug-ins to access external resources with pods

[source,terminal]
----
$ oc create -f devicemgr.yaml
----

## Including pod priority in pod scheduling decisions

[source,terminal]
----
$ oc create -f <file-name>.yaml
----

## Providing sensitive data to pods

[source,terminal]
----
$ oc create -f <filename>
----


[source,terminal]
----
$ oc create -f <file-name>.yaml
----


[source,terminal]
----
$ oc delete secret <secret_name>
----


[source,terminal]
----
$ oc annotate service <service_name> service.alpha.openshift.io/serving-cert-generation-error-
----


[source,terminal]
----
$ oc annotate service <service_name> service.alpha.openshift.io/serving-cert-generation-error-num-
----

## Automatically adjust pod resource levels with the vertical pod autoscaler

[source,terminal]
----
$ oc create -f <file-name>.yaml
----

## Viewing pods

[source,terminal]
----
$ oc adm top pods
----


[source,terminal]
----
$ oc adm top pods -n openshift-console
----


[source,terminal]
----
$ oc adm top pod --selector=''
----

## Evicting pods using the descheduler

[source,terminal]
----
$ oc edit kubedeschedulers.operator.openshift.io cluster -n openshift-kube-descheduler-operator
----


[source,terminal]
----
$ oc edit kubedeschedulers.operator.openshift.io cluster -n openshift-kube-descheduler-operator
----

## Configuring the default scheduler to control pod placement

[source,terminal]
----
$ oc create configmap -n openshift-config --from-file=policy.cfg <configmap-name> 
----


[source,terminal]
----
$ oc create configmap -n openshift-config --from-file=policy.cfg scheduler-policy
----


[source,terminal]
----
$ oc patch Scheduler cluster --type='merge' -p '{"spec":{"policy":{"name":"<configmap-name>"}}}' --type=merge 
----


[source,terminal]
----
$ oc patch Scheduler cluster --type='merge' -p '{"spec":{"policy":{"name":"scheduler-policy"}}}' --type=merge
----


[source,terminal]
----
$ oc edit configmap <configmap-name>  -n openshift-config
----


[source,terminal]
----
$ oc edit configmap scheduler-policy -n openshift-config
----


[source,terminal]
----
$ oc delete configmap -n openshift-config <name>
----


[source,terminal]
----
$ oc delete configmap -n openshift-config  scheduler-policy
----


[source,terminal]
----
$ oc create configmap -n openshift-config --from-file=policy.cfg <configmap-name> 
----


[source,terminal]
----
$ oc create configmap -n openshift-config --from-file=policy.cfg scheduler-policy
----

## Controlling pod placement on nodes using node affinity rules

[source,terminal]
----
$ oc label node node1 e2e-az-name=e2e-az1
----


[source,terminal]
----
$ oc create -f e2e-az2.yaml
----


[source,terminal]
----
$ oc label node node1 e2e-az-name=e2e-az3
----


[source,terminal]
----
$ oc create -f e2e-az3.yaml
----


[source,terminal]
----
$ oc label node node1 zone=us
----


[source,terminal]
----
$ oc label node node1 zone=emea
----

## Placing pods on specific nodes using node selectors

[source,terminal]
----
$ oc patch MachineSet <name> --type='json' -p='[{"op":"add","path":"/spec/template/spec/metadata/labels", "value":{"<key>"="<value>","<key>"="<value>"}}]'  -n openshift-machine-api
----


[source,terminal]
----
$ oc patch MachineSet abc612-msrtw-worker-us-east-1c  --type='json' -p='[{"op":"add","path":"/spec/template/spec/metadata/labels", "value":{"type":"user-node","region":"east"}}]'  -n openshift-machine-api
----


[source,terminal]
----
$ oc edit MachineSet abc612-msrtw-worker-us-east-1c -n openshift-machine-api
----


[source,terminal]
----
$ oc label nodes <name> <key>=<value>
----


[source,terminal]
----
$ oc label nodes ip-10-0-142-25.ec2.internal type=user-node region=east
----


[source,terminal]
----
$ oc edit scheduler cluster
----


[source,terminal]
----
$ oc patch MachineSet <name> --type='json' -p='[{"op":"add","path":"/spec/template/spec/metadata/labels", "value":{"<key>"="<value>","<key>"="<value>"}}]'  -n openshift-machine-api 
----


[source,terminal]
----
$ oc patch MachineSet ci-ln-l8nry52-f76d1-hl7m7-worker-c --type='json' -p='[{"op":"add","path":"/spec/template/spec/metadata/labels", "value":{"type":"user-node","region":"east"}}]'  -n openshift-machine-api
----


[source,terminal]
----
$ oc edit MachineSet ci-ln-l8nry52-f76d1-hl7m7-worker-c -n openshift-machine-api
----


[source,terminal]
----
$ oc scale --replicas=0 MachineSet ci-ln-l8nry52-f76d1-hl7m7-worker-c -n openshift-machine-api
----


[source,terminal]
----
$ oc scale --replicas=1 MachineSet ci-ln-l8nry52-f76d1-hl7m7-worker-c -n openshift-machine-api
----


[source,terminal]
----
$ oc label nodes <name> <key>=<value>
----


[source,terminal]
----
$ oc label nodes ci-ln-l8nry52-f76d1-hl7m7-worker-b-tgq49 type=user-node region=east
----


[source,terminal]
----
$ oc patch MachineSet <name> --type='json' -p='[{"op":"add","path":"/spec/template/spec/metadata/labels", "value":{"<key>"="<value>","<key>"="<value>"}}]'  -n openshift-machine-api
----


[source,terminal]
----
$ oc patch MachineSet ci-ln-l8nry52-f76d1-hl7m7-worker-c --type='json' -p='[{"op":"add","path":"/spec/template/spec/metadata/labels", "value":{"type":"user-node","region":"east"}}]'  -n openshift-machine-api
----


[source,terminal]
----
$ oc edit MachineSet ci-ln-l8nry52-f76d1-hl7m7-worker-c -n openshift-machine-api
----


[source,terminal]
----
$ oc scale --replicas=0 MachineSet ci-ln-l8nry52-f76d1-hl7m7-worker-c -n openshift-machine-api
----


[source,terminal]
----
$ oc scale --replicas=1 MachineSet ci-ln-l8nry52-f76d1-hl7m7-worker-c -n openshift-machine-api
----


[source,terminal]
----
$ oc label <resource> <name> <key>=<value>
----


[source,terminal]
----
$ oc label nodes ci-ln-l8nry52-f76d1-hl7m7-worker-c-tgq49 type=user-node region=east
----

## Placing pods relative to other pods using affinity and anti-affinity rules

[source,terminal]
----
$ oc create -f <pod-spec>.yaml
----


[source,terminal]
----
$ oc create -f <pod-spec>.yaml
----

## Controlling pod placement by using pod topology spread constraints

[source,terminal]
----
$ oc create -f pod-spec.yaml
----

## Scheduling pods using a scheduler profile

[source,terminal]
----
$ oc edit scheduler cluster
----

## Controlling pod placement using node taints

[source,terminal]
----
$ oc adm taint nodes node1 key1=value1:NoSchedule
----


[source,terminal]
----
$ oc adm taint nodes node1 key1=value1:NoExecute
----


[source,terminal]
----
$ oc adm taint nodes node1 key2=value2:NoSchedule
----


[source,terminal]
----
$ oc adm taint nodes <node_name> <key>=<value>:<effect>
----


[source,terminal]
----
$ oc adm taint nodes node1 key1=value1:NoExecute
----


[source,terminal]
----
$ oc edit machineset <machineset>
----


[source,terminal]
----
$ oc scale --replicas=0 machineset <machineset> -n openshift-machine-api
----


[source,terminal]
----
$ oc scale --replicas=2 machineset <machineset> -n openshift-machine-api
----


[source,terminal]
----
$ oc adm taint nodes node1 dedicated=groupName:NoSchedule
----


[source,terminal]
----
$ oc adm taint nodes <node-name> disktype=ssd:NoSchedule
----


[source,terminal]
----
$ oc adm taint nodes <node-name> disktype=ssd:PreferNoSchedule
----


[source,terminal]
----
$ oc adm taint nodes <node-name> <key>-
----


[source,terminal]
----
$ oc adm taint nodes ip-10-0-132-248.ec2.internal key1-
----
